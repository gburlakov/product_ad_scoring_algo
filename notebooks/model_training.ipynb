{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "262e3c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26eaa754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# from preprocessing import preprocess_data  # Make sure this is in the same directory\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4bca970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import input_data_csv_filepath, ad_platform_list, train_size, model_dict, \\\n",
    "target_dict, feature_list, trained_models_folderpath, n_trials_optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2186ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv(input_data_csv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d83593b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>product_age</th>\n",
       "      <th>product_status</th>\n",
       "      <th>pct_product_variants_in_stock</th>\n",
       "      <th>meta_product_revenue</th>\n",
       "      <th>...</th>\n",
       "      <th>google_item_quantity_sold</th>\n",
       "      <th>google_product_detail_views</th>\n",
       "      <th>google_quantity_added_to_cart</th>\n",
       "      <th>google_impressions</th>\n",
       "      <th>google_clicks</th>\n",
       "      <th>google_spend</th>\n",
       "      <th>all_product_revenue</th>\n",
       "      <th>all_item_quantity_sold</th>\n",
       "      <th>all_product_detail_views</th>\n",
       "      <th>all_quantity_added_to_cart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-05-19</td>\n",
       "      <td>000a7fa1-f610-48c5-9ad3-d83d003d061f</td>\n",
       "      <td>oberteile mit bindebändern</td>\n",
       "      <td>29.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>352</td>\n",
       "      <td>DELETED</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-29</td>\n",
       "      <td>000a7fa1-f610-48c5-9ad3-d83d003d061f</td>\n",
       "      <td>oberteile mit bindebändern</td>\n",
       "      <td>29.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>332</td>\n",
       "      <td>DELETED</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-23</td>\n",
       "      <td>000a7fa1-f610-48c5-9ad3-d83d003d061f</td>\n",
       "      <td>oberteile mit bindebändern</td>\n",
       "      <td>29.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326</td>\n",
       "      <td>DELETED</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-27</td>\n",
       "      <td>000a7fa1-f610-48c5-9ad3-d83d003d061f</td>\n",
       "      <td>oberteile mit bindebändern</td>\n",
       "      <td>29.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330</td>\n",
       "      <td>DELETED</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>000a7fa1-f610-48c5-9ad3-d83d003d061f</td>\n",
       "      <td>oberteile mit bindebändern</td>\n",
       "      <td>29.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>348</td>\n",
       "      <td>DELETED</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175397</th>\n",
       "      <td>2025-04-02</td>\n",
       "      <td>fff05380-fae8-44b2-b2ea-f62969ac5706</td>\n",
       "      <td>wide jeans</td>\n",
       "      <td>49.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>PARTIALLY_IN_STOCK</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>195</td>\n",
       "      <td>4</td>\n",
       "      <td>17.950000</td>\n",
       "      <td>2604.766418</td>\n",
       "      <td>5</td>\n",
       "      <td>210</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175398</th>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>fff05380-fae8-44b2-b2ea-f62969ac5706</td>\n",
       "      <td>wide jeans</td>\n",
       "      <td>49.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>PARTIALLY_IN_STOCK</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>553.003926</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>206</td>\n",
       "      <td>13</td>\n",
       "      <td>59.203215</td>\n",
       "      <td>1437.987204</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175399</th>\n",
       "      <td>2025-05-16</td>\n",
       "      <td>fff05380-fae8-44b2-b2ea-f62969ac5706</td>\n",
       "      <td>wide jeans</td>\n",
       "      <td>49.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86</td>\n",
       "      <td>PARTIALLY_IN_STOCK</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>2.685589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175400</th>\n",
       "      <td>2025-05-15</td>\n",
       "      <td>fff05380-fae8-44b2-b2ea-f62969ac5706</td>\n",
       "      <td>wide jeans</td>\n",
       "      <td>49.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "      <td>PARTIALLY_IN_STOCK</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>4</td>\n",
       "      <td>22.974100</td>\n",
       "      <td>930.943889</td>\n",
       "      <td>2</td>\n",
       "      <td>102</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175401</th>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>fff05380-fae8-44b2-b2ea-f62969ac5706</td>\n",
       "      <td>wide jeans</td>\n",
       "      <td>49.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>PARTIALLY_IN_STOCK</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>1418.921823</td>\n",
       "      <td>3</td>\n",
       "      <td>117</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175402 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date                            product_id  \\\n",
       "0       2025-05-19  000a7fa1-f610-48c5-9ad3-d83d003d061f   \n",
       "1       2025-04-29  000a7fa1-f610-48c5-9ad3-d83d003d061f   \n",
       "2       2025-04-23  000a7fa1-f610-48c5-9ad3-d83d003d061f   \n",
       "3       2025-04-27  000a7fa1-f610-48c5-9ad3-d83d003d061f   \n",
       "4       2025-05-15  000a7fa1-f610-48c5-9ad3-d83d003d061f   \n",
       "...            ...                                   ...   \n",
       "175397  2025-04-02  fff05380-fae8-44b2-b2ea-f62969ac5706   \n",
       "175398  2025-04-16  fff05380-fae8-44b2-b2ea-f62969ac5706   \n",
       "175399  2025-05-16  fff05380-fae8-44b2-b2ea-f62969ac5706   \n",
       "175400  2025-05-15  fff05380-fae8-44b2-b2ea-f62969ac5706   \n",
       "175401  2025-05-06  fff05380-fae8-44b2-b2ea-f62969ac5706   \n",
       "\n",
       "                          category  price  sale_price  discount_rate  \\\n",
       "0       oberteile mit bindebändern  29.99         NaN            0.0   \n",
       "1       oberteile mit bindebändern  29.99         NaN            0.0   \n",
       "2       oberteile mit bindebändern  29.99         NaN            0.0   \n",
       "3       oberteile mit bindebändern  29.99         NaN            0.0   \n",
       "4       oberteile mit bindebändern  29.99         NaN            0.0   \n",
       "...                            ...    ...         ...            ...   \n",
       "175397                  wide jeans  49.99         NaN            0.0   \n",
       "175398                  wide jeans  49.99         NaN            0.0   \n",
       "175399                  wide jeans  49.99         NaN            0.0   \n",
       "175400                  wide jeans  49.99         NaN            0.0   \n",
       "175401                  wide jeans  49.99         NaN            0.0   \n",
       "\n",
       "        product_age      product_status  pct_product_variants_in_stock  \\\n",
       "0               352             DELETED                       0.000000   \n",
       "1               332             DELETED                       0.000000   \n",
       "2               326             DELETED                       0.000000   \n",
       "3               330             DELETED                       0.000000   \n",
       "4               348             DELETED                       0.000000   \n",
       "...             ...                 ...                            ...   \n",
       "175397           42  PARTIALLY_IN_STOCK                       0.428571   \n",
       "175398           56  PARTIALLY_IN_STOCK                       0.571429   \n",
       "175399           86  PARTIALLY_IN_STOCK                       0.285714   \n",
       "175400           85  PARTIALLY_IN_STOCK                       0.285714   \n",
       "175401           76  PARTIALLY_IN_STOCK                       0.428571   \n",
       "\n",
       "        meta_product_revenue  ...  google_item_quantity_sold  \\\n",
       "0                   0.000000  ...                          0   \n",
       "1                   0.000000  ...                          0   \n",
       "2                   0.000000  ...                          0   \n",
       "3                   0.000000  ...                          0   \n",
       "4                   0.000000  ...                          0   \n",
       "...                      ...  ...                        ...   \n",
       "175397              0.000000  ...                          0   \n",
       "175398            553.003926  ...                          0   \n",
       "175399              0.000000  ...                          0   \n",
       "175400              0.000000  ...                          0   \n",
       "175401              0.000000  ...                          0   \n",
       "\n",
       "        google_product_detail_views  google_quantity_added_to_cart  \\\n",
       "0                                 0                              0   \n",
       "1                                 0                              0   \n",
       "2                                 0                              0   \n",
       "3                                 0                              0   \n",
       "4                                 0                              0   \n",
       "...                             ...                            ...   \n",
       "175397                           30                              2   \n",
       "175398                           23                              8   \n",
       "175399                           11                              1   \n",
       "175400                           13                              1   \n",
       "175401                            6                              2   \n",
       "\n",
       "        google_impressions  google_clicks  google_spend  all_product_revenue  \\\n",
       "0                        0              0      0.000000             0.000000   \n",
       "1                        0              0      0.000000             0.000000   \n",
       "2                        0              0      0.000000             0.000000   \n",
       "3                        0              0      0.000000             0.000000   \n",
       "4                        0              0      0.000000             0.000000   \n",
       "...                    ...            ...           ...                  ...   \n",
       "175397                 195              4     17.950000          2604.766418   \n",
       "175398                 206             13     59.203215          1437.987204   \n",
       "175399                  98              1      2.685589             0.000000   \n",
       "175400                  99              4     22.974100           930.943889   \n",
       "175401                 144              3     12.700000          1418.921823   \n",
       "\n",
       "        all_item_quantity_sold  all_product_detail_views  \\\n",
       "0                            0                         5   \n",
       "1                            0                         1   \n",
       "2                            0                         1   \n",
       "3                            0                         1   \n",
       "4                            0                         1   \n",
       "...                        ...                       ...   \n",
       "175397                       5                       210   \n",
       "175398                       3                       126   \n",
       "175399                       0                       114   \n",
       "175400                       2                       102   \n",
       "175401                       3                       117   \n",
       "\n",
       "        all_quantity_added_to_cart  \n",
       "0                                0  \n",
       "1                                0  \n",
       "2                                0  \n",
       "3                                0  \n",
       "4                                0  \n",
       "...                            ...  \n",
       "175397                          23  \n",
       "175398                          19  \n",
       "175399                           6  \n",
       "175400                           8  \n",
       "175401                          20  \n",
       "\n",
       "[175402 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae425e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_train_test_val_size(df, val_first_day, val_last_day, train_size, target, features, date_column, prefixes, dummy_columns, \\\n",
    "                            encoding=True):\n",
    "    \"\"\"\n",
    "    Splits the input dataset into train, test, and validation sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing processed product data.\n",
    "        val_first_day (str or pd.Timestamp): First day of the validation period.\n",
    "        val_last_day (str or pd.Timestamp): Last day of the validation period.\n",
    "        train_size (float): Share of data to use for training.\n",
    "        target (str): Target metric to be predicted.\n",
    "        features (list): List of features to train models on.\n",
    "        date_column (str): Name of the date column.\n",
    "        encoding (bool): Whether to apply encoding and scaling to features.\n",
    "    \n",
    "    Returns:\n",
    "        Depending on `encoding`, returns either:\n",
    "            - Encoded version: X_train, X_test, X_val, y_train, y_test, y_val, encoders, scalers\n",
    "            - Raw version: X_val, y_val\n",
    "    \"\"\"\n",
    "    X = df[features + [date_column]].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    y = df[[target, date_column]]\n",
    "\n",
    "    encoders, scalers = {}, {}\n",
    "\n",
    "    if encoding:\n",
    "        for col in features:\n",
    "            if X[col].dtype == 'object':\n",
    "                encoders[col] = LabelEncoder()\n",
    "                X[col] = encoders[col].fit_transform(X[col])\n",
    "        \n",
    "        numerical_cols = X[features].select_dtypes(include=np.number).columns\n",
    "        for col in numerical_cols:\n",
    "            scalers[col] = StandardScaler()\n",
    "            X[col] = scalers[col].fit_transform(X[[col]])\n",
    "\n",
    "    mask_val = (X[date_column] >= val_first_day) & (X[date_column] <= val_last_day)\n",
    "    mask_train_test = X[date_column] < val_first_day\n",
    "\n",
    "    X_val = X[mask_val].copy()\n",
    "    y_val = y[mask_val].copy()\n",
    "\n",
    "    X_train_test = X[mask_train_test].copy()\n",
    "    y_train_test = y[mask_train_test].copy()\n",
    "\n",
    "    drop_date = encoding\n",
    "    if drop_date:\n",
    "        X_val.drop(columns=[date_column], inplace=True)\n",
    "        y_val.drop(columns=[date_column], inplace=True)\n",
    "        X_train_test.drop(columns=[date_column], inplace=True)\n",
    "        y_train_test.drop(columns=[date_column], inplace=True)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train_test, y_train_test, train_size=train_size, random_state=42\n",
    "    )\n",
    "\n",
    "    if encoding:\n",
    "        return X_train, X_test, X_val, y_train, y_test, y_val, encoders, scalers\n",
    "    else:\n",
    "        X_val = X_val.drop(columns=dummy_columns)\n",
    "        print(X_val.info())\n",
    "        return X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94405619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, model_class, param_grid, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Objective function for Optuna optimization\n",
    "    \n",
    "    Args:\n",
    "        trial (optuna.Trial): Optuna trial object\n",
    "        model_class (class): ML method\n",
    "        param_grid (grid): grid with model hyperparameter value sets\n",
    "        model_name (str): name of the model being optimized\n",
    "        X_train (pd.DataFrame): training features\n",
    "        y_train (pd.Series): training target\n",
    "        X_test (pd.DataFrame): testing features\n",
    "        y_test (pd.Series): testing target\n",
    "    \"\"\"\n",
    "    params = {}\n",
    "    for param_name, param_values in param_grid.items():\n",
    "        if isinstance(param_values, list):\n",
    "            if all(isinstance(val, (int, float)) for val in param_values):\n",
    "                if isinstance(param_values[0], int):\n",
    "                    params[param_name] = trial.suggest_int(param_name, min(param_values), max(param_values))\n",
    "                else:\n",
    "                    params[param_name] = trial.suggest_float(param_name, min(param_values), max(param_values))\n",
    "\n",
    "            else:\n",
    "                params[param_name] = trial.suggest_categorical(param_name, param_values)\n",
    " \n",
    "        else:\n",
    "            params = {}\n",
    "\n",
    "    model = model_class.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47ee38a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, ad_platform, target, features, val_last_day_str, trained_models_folderpath, \\\n",
    "                X_train, X_test, y_train, y_test, X_val, y_val, encoders, scalers, model_dict, n_trials_optuna):\n",
    "    \"\"\"\n",
    "    Trains an ensemble of machine learning models for ROI prediction\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing processed product data\n",
    "        ad_platform (str): ad platform, meta or google\n",
    "        target (str): target metric to be trained on\n",
    "        features (list): list of features to train models on\n",
    "        val_last_day_str (str): last date of the validation set as a string\n",
    "        trained_models_folderpath (path): location path of the trained models\n",
    "        X_train (pd.DataFrame): X features of the train set\n",
    "        X_test (pd.DataFrame): X features of the test set\n",
    "        y_train (pd.DataFrame): target y values of the train set\n",
    "        y_test (pd.DataFrame): target y values of the test set\n",
    "        X_val (pd.DataFrame): X features of the validation set\n",
    "        y_val (pd.DataFrame): target y values of the validation set\n",
    "        encoders: encoder labels of columns\n",
    "        scalers: standard scaling of the numeric columns values\n",
    "        model_dict (dict): dictionary with trained model_names, models and parameter grids\n",
    "    \"\"\"\n",
    "    best_models = {}\n",
    "\n",
    "    for model_name, (model_class, param_grid) in model_dict.items():\n",
    "        print(f\"Optimizing {model_name}...\")\n",
    "\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(lambda trial: objective(trial, model_class, param_grid, X_train, y_train, X_test, y_test), n_trials=n_trials_optuna)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        model = model_class.set_params(**best_params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        best_models[model_name] = {'model': model, 'mse': mse, 'r2': r2}\n",
    "        print(f\"{model_name} - Best MSE: {mse}, R2: {r2}, Best Params: {best_params}\")\n",
    "        \n",
    "        individual_model_filename = os.path.join(trained_models_folderpath, \\\n",
    "                                                 f\"{val_last_day_str}_{target}_{model_name}.pkl\")\n",
    "        with open(individual_model_filename, 'wb') as f:\n",
    "            pickle.dump(model, f)        \n",
    "        \n",
    "    top_3_models = sorted(best_models.items(), key=lambda item: item[1]['r2'], reverse=True)[:3]\n",
    "    print(\"\\nTop 3 Models:\")\n",
    "    for model_name, model_data in top_3_models:\n",
    "        print(f\"{model_name}: MSE = {model_data['mse']}, R2 = {model_data['r2']}\")\n",
    "\n",
    "    total_r2 = sum(model_data['r2'] for model_name, model_data in top_3_models)\n",
    "    ensemble_weights = {model_name: model_data['r2'] / total_r2 for model_name, model_data in top_3_models}\n",
    "    print(\"\\nEnsemble Weights:\")\n",
    "    for model_name, weight in ensemble_weights.items():\n",
    "        print(f\"{model_name}: {weight}\")\n",
    "\n",
    "    # Save the ensemble weights, top models, encoders, and scalers\n",
    "    ensemble_data = {\n",
    "        'ensemble_weights': ensemble_weights,\n",
    "        'top_models': {model_name: os.path.join(trained_models_folderpath, \\\n",
    "                                                f\"{val_last_day_str}_{target}_{model_name}.pkl\") \\\n",
    "                       for model_name, model_data in top_3_models},\n",
    "        'features': features\n",
    "    }\n",
    "    \n",
    "    ensemble_model_filename = os.path.join(trained_models_folderpath, \\\n",
    "                                                 f\"{val_last_day_str}_{target}_ensemble.pkl\")\n",
    "    with open(ensemble_model_filename, 'wb') as f:\n",
    "        pickle.dump(ensemble_data, f)\n",
    "    \n",
    "    encoders_filename = os.path.join(trained_models_folderpath, \\\n",
    "                                                     f\"{val_last_day_str}_{target}_encoders.pkl\")    \n",
    "    with open(encoders_filename, 'wb') as f:\n",
    "        pickle.dump(encoders, f)\n",
    "    \n",
    "    scalers_filename = os.path.join(trained_models_folderpath, \\\n",
    "                                                     f\"{val_last_day_str}_{target}_scalers.pkl\")    \n",
    "    with open(scalers_filename, 'wb') as f:\n",
    "        pickle.dump(scalers, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad-score",
   "language": "python",
   "name": "ad-score-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
