{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f18ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ab_test_selection(all_ranked_products_df, all_predictions_df,\n",
    "                      all_actual_products_selected_filepath, all_pred_products_selected_filepath, all_ab_test_results_filepath):\n",
    "    \"\"\"\n",
    "    This function runs an A/B testing assessment of the significance of the difference between average ROI\n",
    "    from the actual product selection and the model implied product selection.\n",
    "    \"\"\"\n",
    "    temp = all_predictions_df.copy()\n",
    "\n",
    "    if 'product_id' not in temp.columns:\n",
    "        temp = temp.reset_index().rename(columns={'index': 'product_id'})\n",
    "\n",
    "    prediction_cols_to_keep = ['product_id', 'model', 'date', 'product_status']\n",
    "    prediction_cols_to_keep = [col for col in prediction_cols_to_keep if col in temp.columns]\n",
    "\n",
    "    # Determine full join keys present in both DataFrames\n",
    "    merge_keys = ['product_id']\n",
    "    for col in ['model', 'date']:\n",
    "        if col in all_ranked_products_df.columns and col in temp.columns:\n",
    "            merge_keys.append(col)\n",
    "\n",
    "    # Perform merge with extended key to avoid duplication\n",
    "    ranked = all_ranked_products_df.merge(\n",
    "        temp[prediction_cols_to_keep],\n",
    "        on=merge_keys,\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    actual_list = []\n",
    "    pred_list = []\n",
    "    ab_list = []\n",
    "\n",
    "    combos = ranked[['category', 'target', 'ad_platform']].drop_duplicates()\n",
    "\n",
    "    for _, combo in combos.iterrows():\n",
    "        cat, tgt, plat = combo['category'], combo['target'], combo['ad_platform']\n",
    "        subset = ranked[\n",
    "            (ranked['category'] == cat) &\n",
    "            (ranked['target'] == tgt) &\n",
    "            (ranked['ad_platform'] == plat)\n",
    "        ]\n",
    "\n",
    "        actual_df = subset[subset['product_status'] != 'DELETED']\n",
    "\n",
    "        L = len(actual_df)\n",
    "        pred_df = subset.nsmallest(L, 'rank')\n",
    "\n",
    "        actual_list.append(actual_df.copy())\n",
    "        pred_list.append(pred_df.copy())\n",
    "        \n",
    "        mean_actual = actual_df['actual'].mean()\n",
    "        mean_pred = pred_df['actual'].mean()\n",
    "\n",
    "        t_stat, p_val = ttest_ind(pred_df['actual'], actual_df['actual'], equal_var=False)\n",
    "\n",
    "        ab_results = pd.DataFrame({\n",
    "            'category': cat,\n",
    "            'target': tgt,\n",
    "            'ad_platform': plat,\n",
    "            'test_statistic': t_stat,\n",
    "            'p_value': p_val,\n",
    "            'mean_actual': mean_actual,\n",
    "            'mean_predicted': mean_pred\n",
    "        }, index=[0])\n",
    "        ab_list.append(ab_results)\n",
    "\n",
    "    all_actual_products_selected_df = pd.concat(actual_list, ignore_index=True).drop_duplicates()\n",
    "    all_pred_products_selected_df   = pd.concat(pred_list,   ignore_index=True).drop_duplicates()\n",
    "    all_ab_test_results_df          = pd.concat(ab_list,     ignore_index=True)\n",
    "\n",
    "    sort_cols = ['product_id', 'category', 'model', 'date']\n",
    "    for df in [all_actual_products_selected_df, all_pred_products_selected_df]:\n",
    "        df.sort_values(by=[col for col in sort_cols if col in df.columns], inplace=True)\n",
    "\n",
    "    all_actual_products_selected_df.to_csv(all_actual_products_selected_filepath, index=False)\n",
    "    all_pred_products_selected_df.to_csv(all_pred_products_selected_filepath, index=False)\n",
    "    all_ab_test_results_df.to_csv(all_ab_test_results_filepath, index=False)\n",
    "\n",
    "    return all_actual_products_selected_df, all_pred_products_selected_df, all_ab_test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1439119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ab_test_selection(all_ranked_products_df, all_predictions_df, \\\n",
    "#                       all_actual_products_selected_filepath, all_pred_products_selected_filepath, all_ab_test_results_filepath):\n",
    "#     \"\"\"\n",
    "#     This function runs an A/B testing assessment of the significance of the difference between average ROI\n",
    "#     from the actual product selection and the model implied product selection\n",
    "#     \"\"\"\n",
    "#     temp = all_predictions_df.copy()\n",
    "#     if 'product_id' not in temp.columns:\n",
    "#         temp = temp.reset_index().rename(columns={'index':'product_id'})\n",
    "\n",
    "#     ranked = all_ranked_products_df.merge(\n",
    "#         temp[['product_id','product_status']],\n",
    "#         on='product_id', how='left'\n",
    "#     )\n",
    "\n",
    "#     actual_list = []\n",
    "#     pred_list = []\n",
    "#     ab_list = []\n",
    "\n",
    "#     combos = ranked[['category','target','ad_platform']].drop_duplicates()\n",
    "#     for _, combo in combos.iterrows():\n",
    "#         cat, tgt, plat = combo['category'], combo['target'], combo['ad_platform']\n",
    "#         subset = ranked[\n",
    "#             (ranked['category']==cat) &\n",
    "#             (ranked['target']==tgt) &\n",
    "#             (ranked['ad_platform']==plat)\n",
    "#         ]\n",
    "\n",
    "#         actual_df = subset[subset['product_status']!='DELETED']\n",
    "\n",
    "#         L = len(actual_df)\n",
    "#         pred_df = subset.nsmallest(L, 'rank')\n",
    "\n",
    "\n",
    "#         actual_list.append(actual_df)\n",
    "#         pred_list.append(pred_df)\n",
    "\n",
    "\n",
    "#         mean_actual = actual_df['actual'].mean()\n",
    "#         mean_pred   = pred_df['actual'].mean()\n",
    "\n",
    "#         t_stat, p_val = ttest_ind(pred_df['actual'], actual_df['actual'], equal_var=False)\n",
    "\n",
    "#         ab_results = pd.DataFrame({\n",
    "#             'category': cat,\n",
    "#             'target': tgt,\n",
    "#             'ad_platform': plat,\n",
    "#             'test_statistic': t_stat,\n",
    "#             'p_value': p_val,\n",
    "#             'mean_actual': mean_actual,\n",
    "#             'mean_predicted': mean_pred\n",
    "#         }, index=[0])\n",
    "#         ab_list.append(ab_results)\n",
    "\n",
    "#     all_actual_products_selected_df = pd.concat(actual_list, ignore_index=True)\n",
    "#     all_pred_products_selected_df   = pd.concat(pred_list,   ignore_index=True)\n",
    "#     all_ab_test_results_df          = pd.concat(ab_list,     ignore_index=True)\n",
    "    \n",
    "#     all_actual_products_selected_df.drop_duplicates()\n",
    "#     all_pred_products_selected_df.drop_duplicates()\n",
    "    \n",
    "#     all_actual_products_selected_df.to_csv(all_actual_products_selected_filepath, index=False)\n",
    "#     all_pred_products_selected_df.to_csv(all_pred_products_selected_filepath, index=False)\n",
    "#     all_ab_test_results_df.to_csv(all_ab_test_results_filepath, index=False)\n",
    "\n",
    "#     return all_actual_products_selected_df, all_pred_products_selected_df, all_ab_test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29493c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ab_test_selection(all_ranked_products_df, all_predictions_df):\n",
    "#     \"\"\"\n",
    "#     This function runs an A/B testing assessment of the significance of the difference between average ROI\n",
    "#     from the actual product selection and the model implied product selection\n",
    "#     \"\"\"\n",
    "#     ranked = all_ranked_products_df.merge(\n",
    "#         all_predictions_df[['product_id','product_status']],\n",
    "#         on='product_id', how='left'\n",
    "#     )\n",
    "\n",
    "#     actual_list = []\n",
    "#     pred_list = []\n",
    "#     ab_list = []\n",
    "#     combos = ranked[['category','target','ad_platform']].drop_duplicates()\n",
    "#     for _, row in combos.iterrows():\n",
    "#         cat, tgt, plat = row['category'], row['target'], row['ad_platform']\n",
    "#         df_sub = ranked[\n",
    "#             (ranked['category']==cat) &\n",
    "#             (ranked['target']==tgt) &\n",
    "#             (ranked['ad_platform']==plat)\n",
    "#         ]\n",
    "#         actual_df = df_sub[df_sub['product_status']=='DELETED']\n",
    "#         L = len(actual_df)\n",
    "#         pred_df = df_sub.head(L)\n",
    "#         actual_list.append(actual_df)\n",
    "#         pred_list.append(pred_df)\n",
    "\n",
    "#         m_actual = actual_df['actual'].mean()\n",
    "#         m_pred   = pred_df['actual'].mean()\n",
    "\n",
    "#         t_stat, p_val = ttest_ind(pred_df['actual'], actual_df['actual'], equal_var=False)\n",
    "\n",
    "#         ab = pred_df.copy()\n",
    "#         ab['test_statistic'] = t_stat\n",
    "#         ab['p_value'] = p_val\n",
    "#         ab_list.append(ab)\n",
    "\n",
    "#     all_actual = pd.concat(actual_list, ignore_index=True)\n",
    "#     all_pred   = pd.concat(pred_list,   ignore_index=True)\n",
    "#     all_ab     = pd.concat(ab_list,     ignore_index=True)\n",
    "\n",
    "#     all_actual.to_csv('all_actual_products_selected.csv', index=False)\n",
    "#     all_pred.to_csv('all_pred_products_selected.csv', index=False)\n",
    "#     all_ab.to_csv('all_actual_pred_ab_test.csv', index=False)\n",
    "    \n",
    "#     return all_actual, all_pred, all_ab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad-score",
   "language": "python",
   "name": "ad-score-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
